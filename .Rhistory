abline(h=30, col="blue")
pdf("Comparison_Sensitivity.pdf")
matplot(Comparison_Questions_AdminNA[c(150:256),c(1:4)], type = c("b"), pch=1, col=1:4, xlab = "Question", ylab = "# of Countries who Skipped")
legend("topleft", legend = c("50", "75", "90", "100"), col=1:4, pch=1)
abline(h=10)
abline(h=20, col="red")
abline(h=15, col="grey")
abline(h=30, col="blue")
dev.off()
#Remove the rows that are greater than 15 in from the 50% analysis.
QuestionstoRemove <- row.names(as.data.frame(which(QuestionCount50[,1] >= 15)))
Reduced_Questions <- subset(t(QuestionCount50), select = -c(which(QuestionCount50[,1] >= 15)))
Reduced_Admin_DF_All<- subset(Admin_DF_All, select = - c( V74B, V90,V91,V92,V93,V94,
v160A,v160B,v160C,v160D,v160E,v160F,v160G,v160H,v160I,v160J,
V217_ESMA,V218_ESMA,V224_ESMA,V220_ESMA,V221_ESMA,V222_ESMA,
V228A,V228B,V228C,V228D,V228E,V228F,V228G,V228H,V228I,V228J,V228K,
V243_AU,V244_AU,V56_NZ,V203A,V207A))
QuestionstoRemove
ReducedAdminNAQuestionCount <- c()
for(i in 1:60){
count = sum(Reduced_Admin_DF_All[i,] == 100)
ReducedAdminNAQuestionCount <- rbind(ReducedAdminNAQuestionCount, count)
}
rownames(ReducedAdminNAQuestionCount) <- rownames(Reduced_Admin_DF_All)
sort(ReducedAdminNAQuestionCount, decreasing = TRUE)
pdf("ReducedAdminNAQuestionCount.pdf")
barplot(t(ReducedAdminNAQuestionCount), xlab = "Countries", ylab = "Number of Questions Skipped")
abline(h=5)
abline(h=10, col="red")
abline(h=15, col="grey")
abline(h=20, col="blue")
dev.off()
#To see which questions they skipped
Removed_Countries_AdminNA <- Reduced_Admin_DF_All[rownames(Reduced_Admin_DF_All) %in% c(414, 634,48,818), ]
pdf("Questionstheyskipped.pdf")
matplot(t(Removed_Countries_AdminNA), type = c("p"), pch=1, col=1:4, xlab = "Question", ylab = "% of People not asked Question")
legend("topleft", legend = row.names(Removed_Countries_AdminNA), col=1:4, pch=1)
dev.off()
Missing_DF_All<- as.data.frame(cbind(Missing_DF, Missing_DF_Ordinal))
colSums(is.na(Missing_DF_All)) #double checking that there are no NAs
QuestionCount50 = c()
count=0 #reset count
for(i in 1:256){
count = sum(Missing_DF_All[,i] >= 50)
QuestionCount50 <- rbind(QuestionCount50, count)
}
rownames(QuestionCount50)<-colnames(Missing_DF_All) #label with question names
barplot(t(QuestionCount50), xlab = "Question", ylab = "Number of Countries who Skipped", main = "50% or Greater Missing")
abline(h=15)
abline(h=20, col="red")
abline(h=25, col="grey")
abline(h=30, col="blue")
QuestionCount75 = c()
count=0 #reset count
for(i in 1:256){
count = sum(Missing_DF_All[,i] >= 75)
QuestionCount75 <- rbind(QuestionCount75, count)
}
rownames(QuestionCount75)<-colnames(Missing_DF_All) #label with question names
barplot(t(QuestionCount75), xlab = "Question", ylab = "Number of Countries who Skipped", main = "75% or Greater Missing")
abline(h=15)
abline(h=20, col="red")
abline(h=25, col="grey")
abline(h=30, col="blue")
QuestionCount90 = c()
count=0 #reset count
for(i in 1:256){
count = sum(Missing_DF_All[,i] >= 90)
QuestionCount90 <- rbind(QuestionCount90, count)
}
rownames(QuestionCount90)<-colnames(Missing_DF_All) #label with question names
barplot(t(QuestionCount90), xlab = "Question", ylab = "Number of Countries who Skipped", main = "90% or Greater Missing")
abline(h=15)
abline(h=20, col="red")
abline(h=25, col="grey")
abline(h=30, col="blue")
QuestionCount100 = c()
count=0 #reset count
for(i in 1:256){
count = sum(Missing_DF_All[,i] == 100)
QuestionCount100 <- rbind(QuestionCount100, count)
}
rownames(QuestionCount100)<-colnames(Missing_DF_All) #label with question names
barplot(t(QuestionCount100), xlab = "Question", ylab = "Number of Countries who Skipped", main = "100% Missing")
abline(h=15)
abline(h=20, col="red")
abline(h=25, col="grey")
abline(h=30, col="blue")
Comparison_Questions_Missing <- cbind(QuestionCount50,QuestionCount75,QuestionCount90,QuestionCount100)
pdf("Comparison_Sensitivity - Missing(-2).pdf")
matplot(Comparison_Questions_Missing[c(1:256),c(1:4)], type = c("b"), pch=1, col=1:4, xlab = "Question", ylab = "# of Countries who Skipped")
legend("topleft", legend = c("50", "75", "90", "100"), col=1:4, pch=1)
abline(h=10)
abline(h=20, col="red")
abline(h=15, col="grey")
abline(h=30, col="blue")
dev.off()
#Remove the rows that are greater than 15 in from the 50% analysis.
QuestionstoRemove <- row.names(as.data.frame(which(QuestionCount50[,1] >= 15)))
Reduced_Questions <- subset(t(QuestionCount50), select = -c(which(QuestionCount50[,1] >= 15)))
QuestionstoRemove
DontKnow_DF_All<- as.data.frame(cbind(Dontknow_DF, DontKnow_DF_Ordinal))
colSums(is.na(DontKnow_DF_All)) #double checking that there are no NAs
QuestionCount50 = c()
count=0 #reset count
for(i in 1:256){
count = sum(DontKnow_DF_All[,i] >= 50)
QuestionCount50 <- rbind(QuestionCount50, count)
}
rownames(QuestionCount50)<-colnames(DontKnow_DF_All) #label with question names
barplot(t(QuestionCount50), xlab = "Question", ylab = "Number of Countries who Skipped", main = "50% or Greater DontKnow")
abline(h=15)
abline(h=20, col="red")
abline(h=25, col="grey")
abline(h=30, col="blue")
QuestionCount75 = c()
count=0 #reset count
for(i in 1:256){
count = sum(DontKnow_DF_All[,i] >= 75)
QuestionCount75 <- rbind(QuestionCount75, count)
}
rownames(QuestionCount75)<-colnames(DontKnow_DF_All) #label with question names
barplot(t(QuestionCount75), xlab = "Question", ylab = "Number of Countries who Skipped", main = "75% or Greater DontKnow")
abline(h=15)
abline(h=20, col="red")
abline(h=25, col="grey")
abline(h=30, col="blue")
QuestionCount90 = c()
count=0 #reset count
for(i in 1:256){
count = sum(DontKnow_DF_All[,i] >= 90)
QuestionCount90 <- rbind(QuestionCount90, count)
}
rownames(QuestionCount90)<-colnames(DontKnow_DF_All) #label with question names
barplot(t(QuestionCount90), xlab = "Question", ylab = "Number of Countries who Skipped", main = "90% or Greater DontKnow")
abline(h=15)
abline(h=20, col="red")
abline(h=25, col="grey")
abline(h=30, col="blue")
QuestionCount100 = c()
count=0 #reset count
for(i in 1:256){
count = sum(DontKnow_DF_All[,i] == 100)
QuestionCount100 <- rbind(QuestionCount100, count)
}
rownames(QuestionCount100)<-colnames(DontKnow_DF_All) #label with question names
barplot(t(QuestionCount100), xlab = "Question", ylab = "Number of Countries", main = "100% DontKnow")
abline(h=15)
abline(h=20, col="red")
abline(h=25, col="grey")
abline(h=30, col="blue")
Comparison_Questions_DontKnow <- cbind(QuestionCount50,QuestionCount75,QuestionCount90, QuestionCount100)
matplot(Comparison_Questions_DontKnow[c(1:256),c(1:4)], type = c("b"), pch=1, col=1:4, xlab = "Question", ylab = "# of Countries")
legend("topleft", legend = c("50", "75", "90", "100"), col=1:4, pch=1)
abline(h=10)
abline(h=20, col="red")
abline(h=15, col="grey")
abline(h=30, col="blue")
pdf("Comparison_Sensitivity - DontKnow(-1).pdf")
matplot(Comparison_Questions_DontKnow[c(200:256),c(1:4)], type = c("b"), pch=1, col=1:4, xlab = "Question", ylab = "# of Countries")
legend("topleft", legend = c("50", "75", "90", "100"), col=1:4, pch=1)
abline(h=10)
abline(h=20, col="red")
abline(h=15, col="grey")
abline(h=30, col="blue")
dev.off()
#Remove the rows that are greater than 15 in from the 50% analysis.
QuestionstoRemove <- row.names(as.data.frame(which(QuestionCount50[,1] >= 15)))
Reduced_Questions <- subset(t(QuestionCount50), select = -c(which(QuestionCount50[,1] >= 15)))
QuestionstoRemove
#This step removes questions from sensitivity analysis above
Cat_Precentage_DFs <- cbind(V4,V5,V6,V7,V8,V9,V10,V11,V12,V13,V14,V15,V16,V17,V18,V19,V20,V21,V22,V25,V26,V27,V28,
V29,V30,V31,V32,V33,V34,V35,V37,V42,V39,V38,V36,V40,V41,V43,V44,V24,V70,V71,V72,V73,V75,
V76, V77,V78,V79,V74,V164,V165,V166,V167,V168,V169,V81,V82,V83,V45,V46,
V102,V49,V54,V51,V52,V50,V48,V47,V53,
V60,V61,V62,V63,V64,V65,V66,V67,V68,V69,V80,V84,V85,V86,V87,V88,V89,V108,V109,V110,V111,V112,
V113,V114,V115,V116,V117,V118,V119,V120,V121,V122,V123,V124,V126,V127,V128,V129,V130,V142,
V217,V218,V219,V220,V221,V222,V223,V224,V225,V226,V227,
V143,V145,V146,V147,V148,V149,V150,V151,V153,V154,V155,V156,
V211,V103,V104,V106,V107,V212,V213,V214,V216,V243,V244,V245,V246,
V170,V171,V172,V173,V174,V175,V176,V177,V178,V179,V180,V181,V182,V183,V184,V185,V186,V187,V188,
V189,V190,V191)
#Remove the columns that are just zeros. This step removes categories that were not used by questions.
Cat_Final_Precentage_DFs<- Cat_Precentage_DFs[,-(which(colSums(Cat_Precentage_DFs) == 0))]
Ordinal_Final_Precentage_DFs <- cbind(V23_Category,
V56_Category,V55_Category,V157_Category,V158_Category,V159_Category,
V160_Category,V164_Category,V59_Category,V95_Category,V96_Category,V97_Category,
V98_Category,V99_Category,V100_Category,V101_Category,V131_Category,V132_Category,
V134_Category,V135_Category,V136_Category,V137_Category,V138_Category,
V141_Category,V192_Category,V194_Category,
V197_Category,V198_Category,V200_Category,V209_Category,
V210_Category,V199_Category,V201_Category,V202_Category,V203_Category,
V204_Category,V205_Category,V207_Category, V206_Category,V208_Category,
V231_Category,V232_Category,V233_Category,V239_Category,
PFL_5Scale_Cat)
Cleaned_Categorical_Ordinal_Data <- cbind(Cat_Final_Precentage_DFs,Ordinal_Final_Precentage_DFs)
#We need to remove the countries chosen above
Cleaned_Categorical_Ordinal_Data_56 <- Cleaned_Categorical_Ordinal_Data[!rownames( Cleaned_Categorical_Ordinal_Data) %in% c(414, 634,48,818), ]
#Now that we have completed the sensitiviy analysis we need to remove all the "AdminNA" Columns
WVS_Data_Precentages1<- Cleaned_Categorical_Ordinal_Data_56[, -grep("Admin", colnames(Cleaned_Categorical_Ordinal_Data_56))]
#Now that we have completed the sensitiviy analysis we need to remove all the "Missing" Columns
WVS_Data_Precentages2<- WVS_Data_Precentages1[, -grep("Missing", colnames(WVS_Data_Precentages1))]
#Now that we have completed the sensitiviy analysis we need to remove all the "Neg1" Columns
WVS_Data_Precentages3<- WVS_Data_Precentages2[, -grep("Neg1", colnames(WVS_Data_Precentages2))]
WVS_Data_Precentages4<- WVS_Data_Precentages3[, -grep("Know", colnames(WVS_Data_Precentages3))]
View(V164_Category)
View(V164_Count)
View(V164)
#This step removes questions from sensitivity analysis above
Cat_Precentage_DFs <- cbind(V4,V5,V6,V7,V8,V9,V10,V11,V12,V13,V14,V15,V16,V17,V18,V19,V20,V21,V22,V25,V26,V27,V28,
V29,V30,V31,V32,V33,V34,V35,V37,V42,V39,V38,V36,V40,V41,V43,V44,V24,V70,V71,V72,V73,V75,
V76, V77,V78,V79,V74,V165,V166,V167,V168,V169,V81,V82,V83,V45,V46,
V102,V49,V54,V51,V52,V50,V48,V47,V53,
V60,V61,V62,V63,V64,V65,V66,V67,V68,V69,V80,V84,V85,V86,V87,V88,V89,V108,V109,V110,V111,V112,
V113,V114,V115,V116,V117,V118,V119,V120,V121,V122,V123,V124,V126,V127,V128,V129,V130,V142,
V217,V218,V219,V220,V221,V222,V223,V224,V225,V226,V227,
V143,V145,V146,V147,V148,V149,V150,V151,V153,V154,V155,V156,
V211,V103,V104,V106,V107,V212,V213,V214,V216,V243,V244,V245,V246,
V170,V171,V172,V173,V174,V175,V176,V177,V178,V179,V180,V181,V182,V183,V184,V185,V186,V187,V188,
V189,V190,V191)
#Remove the columns that are just zeros. This step removes categories that were not used by questions.
Cat_Final_Precentage_DFs<- Cat_Precentage_DFs[,-(which(colSums(Cat_Precentage_DFs) == 0))]
Ordinal_Final_Precentage_DFs <- cbind(V23_Category,
V56_Category,V55_Category,V157_Category,V158_Category,V159_Category,
V160_Category,V164_Category,V59_Category,V95_Category,V96_Category,V97_Category,
V98_Category,V99_Category,V100_Category,V101_Category,V131_Category,V132_Category,
V134_Category,V135_Category,V136_Category,V137_Category,V138_Category,
V141_Category,V192_Category,V194_Category,
V197_Category,V198_Category,V200_Category,V209_Category,
V210_Category,V199_Category,V201_Category,V202_Category,V203_Category,
V204_Category,V205_Category,V207_Category, V206_Category,V208_Category,
V231_Category,V232_Category,V233_Category,V239_Category,
PFL_5Scale_Cat)
Cleaned_Categorical_Ordinal_Data <- cbind(Cat_Final_Precentage_DFs,Ordinal_Final_Precentage_DFs)
#We need to remove the countries chosen above
Cleaned_Categorical_Ordinal_Data_56 <- Cleaned_Categorical_Ordinal_Data[!rownames( Cleaned_Categorical_Ordinal_Data) %in% c(414, 634,48,818), ]
#Now that we have completed the sensitiviy analysis we need to remove all the "AdminNA" Columns
WVS_Data_Precentages1<- Cleaned_Categorical_Ordinal_Data_56[, -grep("Admin", colnames(Cleaned_Categorical_Ordinal_Data_56))]
#Now that we have completed the sensitiviy analysis we need to remove all the "Missing" Columns
WVS_Data_Precentages2<- WVS_Data_Precentages1[, -grep("Missing", colnames(WVS_Data_Precentages1))]
#Now that we have completed the sensitiviy analysis we need to remove all the "Neg1" Columns
WVS_Data_Precentages3<- WVS_Data_Precentages2[, -grep("Neg1", colnames(WVS_Data_Precentages2))]
WVS_Data_Precentages4<- WVS_Data_Precentages3[, -grep("Know", colnames(WVS_Data_Precentages3))]
#write.csv(WVS_Data_Precentages, file = "WVS_Data_Percentages.csv")
Variances <- c()
for(i in 1:895){
Question_Variance <- var(WVS_Data_Precentages3[,i])
Variances <- cbind(Variances, Question_Variance)
}
Variances <- c()
for(i in 1:835){
Question_Variance <- var(WVS_Data_Precentages4[,i])
Variances <- cbind(Variances, Question_Variance)
}
colnames(Variances)<-colnames(WVS_Data_Precentages3)
Variances <- c()
for(i in 1:835){
Question_Variance <- var(WVS_Data_Precentages4[,i])
Variances <- cbind(Variances, Question_Variance)
}
colnames(Variances)<-colnames(WVS_Data_Precentages4)
Variance_Sorted <- t(Variances)
#pdf("Variance distribution.pdf", paper = "USr")
par(mfrow=c(2, 1))
hist(Variances)
barplot(Variances)
#dev.off()
#Break into two groups - Questions with 2 answers and those with more than 2 answers.
#Two answer questions: 12-22, 24, 36-44, 66, 82, 83, 148, 149, 150, 151, 176, 177, 178, 179, 180, 234, 235, 236, 240, 243, 244, 245,246, 250, 252
TwoCategoryQuestions<- WVS_Data_Precentages4[,c("V24_1","V24_2",
"V66_1","V66_2",
"V82_1","V82_2",
"V83_1","V83_2" ,
"V148_1","V148_2",
"V149_1","V149_2",
"V150_1","V150_2",
"V151_1","V151_2",
"V176_1","V176_5",
"V177_1","V177_5",
"V178_1","V178_5",
"V179_1","V179_5",
"V180_1","V180_5",
"V187_1", "V187_2",
"V243_1","V243_2",
"V244_1","V244_2",
"V245_1","V245_2",
"V246_1","V246_2")]
Variances_TwoCategory<- c()
for(i in 1:36){
Question_Variance_TwoCategory <- var(TwoCategoryQuestions[,i])
Variances_TwoCategory <- cbind(Variances_TwoCategory, Question_Variance_TwoCategory)
}
colnames(Variances_TwoCategory)<-colnames(TwoCategoryQuestions)
Variance_Sorted_TwoCategory <- t(Variances_TwoCategory)
pdf("Variance_TwoCategory distribution.pdf", paper = "USr")
par(mfrow=c(2, 1))
hist(Variances_TwoCategory)
barplot(Variances_TwoCategory)
dev.off()
MentionQuestions<- WVS_Data_Precentages4[,c("V12_1", "V12_2",
"V13_1", "V13_2",
"V14_1", "V14_2",
"V15_1", "V15_2",
"V16_1", "V16_2",
"V17_1", "V17_2",
"V18_1", "V18_2",
"V19_1", "V19_2",
"V20_1", "V20_2",
"V21_1", "V21_2",
"V22_1", "V22_2",
"V36_1", "V36_2",
"V37_1", "V37_2",
"V38_1", "V38_2",
"V39_1", "V39_2",
"V40_1", "V40_2",
"V41_1", "V41_2",
"V42_1", "V42_2",
"V43_1", "V43_2",
"V44_1", "V44_2")]
Variances_Mention<- c()
for(i in 1:40){
Question_Variance_Mention <- var(MentionQuestions[,i])
Variances_Mention <- cbind(Variances_Mention, Question_Variance_Mention)
}
colnames(Variances_Mention)<-colnames(MentionQuestions)
Variance_Sorted_Mention<- t(Variances_Mention)
#pdf("Variance_Mention distribution.pdf", paper = "USr")
par(mfrow=c(2, 1))
hist(Variances_Mention)
barplot(Variances_Mention)
#dev.off()
remove <- c(colnames(TwoCategoryQuestions), colnames(MentionQuestions))
MultipleCat_Questions<- WVS_Data_Precentages4[,!colnames(WVS_Data_Precentages4) %in% remove]
Variances_MultipleCat<- c()
for(i in 1:798){
Question_Variance_MultipleCat <- var(MultipleCat_Questions[,i])
Variances_MultipleCat <- cbind(Variances_MultipleCat, Question_Variance_MultipleCat)
}
MultipleCat_Questions<- WVS_Data_Precentages4[,!colnames(WVS_Data_Precentages4) %in% remove]
remove <- c(colnames(TwoCategoryQuestions), colnames(MentionQuestions))
MultipleCat_Questions<- WVS_Data_Precentages4[,!colnames(WVS_Data_Precentages4) %in% remove]
Variances_MultipleCat<- c()
for(i in 1:759){
Question_Variance_MultipleCat <- var(MultipleCat_Questions[,i])
Variances_MultipleCat <- cbind(Variances_MultipleCat, Question_Variance_MultipleCat)
}
colnames(Variances_MultipleCat)<-colnames(MultipleCat_Questions)
Variance_Sorted_MultipleCat<- t(Variances_MultipleCat)
#pdf("Variance_MultipleCat distribution.pdf", paper = "USr")
par(mfrow=c(2, 1))
hist(Variances_MultipleCat)
barplot(Variances_MultipleCat)
#dev.off()
BinaryQuestions_RemoveVarible <- colnames(WVS_Data_Precentages4[,c("V12_2","V13_2", "V14_2", "V15_2",
"V16_2", "V17_2", "V18_2",
"V19_2",  "V20_2", "V21_2",
"V22_2", "V36_2", "V37_2",
"V38_2",  "V39_2", "V40_2",
"V41_2",  "V42_2", "V43_2",
"V44_2", "V24_2", "V66_2",
"V82_2","V83_2","V148_2","V149_2",
"V150_2", "V151_2","V176_5", "V177_5",
"V178_5","V179_5","V180_5","V187_2","V243_2",
"V244_2","V245_2", "V246_2")])
WVS_Data_Precentages5 <- WVS_Data_Precentages4[,!colnames(WVS_Data_Precentages4) %in% BinaryQuestions_RemoveVarible]
normality_test <- apply(WVS_Data_Precentages5, 2, ad.test)
#Need to determine which variables have significant p-values
normality_p.values <- c()
variable_names <- colnames(WVS_Data_Precentages5)
for(col in c(1:810)){
variable_normality <- normality_test[[col]]
p.value <- variable_normality$p.value
normality_p.values <- cbind(normality_p.values, p.value)
}
normality_p.values <- c()
variable_names <- colnames(WVS_Data_Precentages5)
for(col in c(1:797)){
variable_normality <- normality_test[[col]]
p.value <- variable_normality$p.value
normality_p.values <- cbind(normality_p.values, p.value)
}
colnames(normality_p.values) <-variable_names
nonnormal_variables <- t(normality_p.values)
nonnormal_variables[nonnormal_variables > 0.05] = NA
View(nonnormal_variables)
nonnormal_variables[nonnormal_variables > 0.05] = NA
nonnormal_variables[nonnormal_variables > 0.01] = NA
hist(V33_2)
hist(V33$V33_2)
View(V33)
d <- dist(WVS_Data_Precentages5, method = "euclidean") # distance matrix
fit <- hclust(d, method="ward")
plot(fit) # display dendogram
groups <- cutree(fit, k=5) # cut tree into 5 clusters
rect.hclust(fit, k=5, border="red")
plot(fit) # display dendogram
groups <- cutree(fit, k=5) # cut tree into 5 clusters
rect.hclust(fit, k=5, border="red")
plot(fit) # display dendogram
groups <- cutree(fit, k=5) # cut tree into 5 clusters
# draw dendogram with red borders around the 5 clusters
rect.hclust(fit, k=5, border="red")
d <- dist(t(WVS_Data_Precentages5), method = "euclidean") # distance matrix
fit <- hclust(d, method="ward")
plot(fit) # display dendogram
rect.hclust(fit, k=5, border="red")
plot(fit) # display dendogram
groups <- cutree(fit, k=5) # cut tree into 5 clusters
# draw dendogram with red borders around the 5 clusters
rect.hclust(fit, k=5, border="red")
hist(V4$V4_4)
hist(V107$V107_3)
install.packages("fastICA")
library("fastICA")
fastICA()
?fastICA
fastICA(WVS_Data_Precentages5, 5)
ICA <- fastICA(WVS_Data_Precentages5, 5)
plot(ICA$S[,1])
ad.test(WVS_Data_Precentages5)
install.packages("MVN")
mulitvariate_normal <- mardiaTest(WVS_Data_Precentages5, qqplot=FALSE)
library("MVN")
mulitvariate_normal <- mardiaTest(WVS_Data_Precentages5, qqplot=FALSE)
mulitvariate_normal <- hzTest(WVS_Data_Precentages5, qqplot=FALSE)
mulitvariate_normal <- roystonTest(WVS_Data_Precentages5, qqplot=FALSE)
BinaryQuestions_RemoveVarible <- colnames(WVS_Data_Precentages4[,c("V12_2","V13_2", "V14_2", "V15_2",
"V16_2", "V17_2", "V18_2",
"V19_2",  "V20_2", "V21_2",
"V22_2", "V36_2", "V37_2",
"V38_2",  "V39_2", "V40_2",
"V41_2",  "V42_2", "V43_2",
"V44_2", "V24_2", "V66_2",
"V82_2","V83_2","V148_2","V149_2",
"V150_2", "V151_2","V176_5", "V177_5",
"V178_5","V179_5","V180_5","V187_2","V243_2",
"V244_2","V245_2", "V246_2")])
WVS_Data_Precentages5 <- WVS_Data_Precentages4[,!colnames(WVS_Data_Precentages4) %in% BinaryQuestions_RemoveVarible]
mulitvariate_normal <- roystonTest(WVS_Data_Precentages5, qqplot=FALSE)
mulitvariate_normal <- roystonTest(WVS_Data_Precentages5, qqplot=FALSE, tol=1e-30)
mardiaTest(?)
?mardiaTest
mulitvariate_normal <- M(WVS_Data_Precentages5, qqplot=FALSE, tol=1e-30)
mulitvariate_normal <- mardiaTest(WVS_Data_Precentages5, qqplot=FALSE, tol=1e-30)
mulitvariate_normal <- mardiaTest(WVS_Data_Precentages5, qqplot=FALSE)
mulitvariate_normal <- mardiaTest(WVS_Data_Precentages5, cov=FALSE, qqplot=FALSE)
mulitvariate_normal <- mardiaTest(WVS_Data_Precentages5[,c(1:60)], qqplot=FALSE)
mulitvariate_normal <- mardiaTest(WVS_Data_Precentages5[,c(1:56)], qqplot=FALSE)
View(WVS_Data_Precentages5)
cor(WVS_Data_Precentages5$V4_1,WVS_Data_Precentages5$)
cor(WVS_Data_Precentages5$V4_1,WVS_Data_Precentages5$V4_2)
cor(WVS_Data_Precentages5$V4_1,WVS_Data_Precentages5$V4_3)
4
cor(WVS_Data_Precentages5$V4_1,WVS_Data_Precentages5$V4_4)
corrplot(WVS_Data_Precentages5)
corrplot(WVS_Data_Precentages5, is.corr=FALSE)
?corrplot
corrplot(as.matrix(WVS_Data_Precentages5), is.corr=FALSE)
corrplot(as.matrix(WVS_Data_Precentages5[,1:50]), is.corr=FALSE)
corrplot(cor(as.matrix(WVS_Data_Precentages5[,1:50])), is.corr=FALSE)
corrplot(cor(as.matrix(WVS_Data_Precentages5[,101:150])), is.corr=FALSE)
nonnormal_variables <- na.omit(nonnormal_variables)
?ad.text
?ad.test
normal_variables <- normality_p.values[normality_p.values<0.01 = NA]
normal_variables <- normality_p.values[normality_p.values < 0.01 = NA]
normality_p.values[normality_p.values < 0.01 = NA]
View(normality_p.values)
normal_variables <- t(normality_p.values)
normal_variables [normal_variables < 0.01 = NA]
View(normal_variables)
normal_variables$V1[1]
normal_variables <- t(normality_p.values)
normal_variables[normal_variables < 0.01] = NA
normal_variables <- na.omit(normal_variables)
View(nonnormal_variables)
View(country_sums)
?prcomp
View(V135_Count)
corrplot(cor(as.matrix(WVS_Data_Precentages5[,101:150])), is.corr=FALSE)
corrplot(cor(V136_Count))
corrplot(cor(as.matrix(WVS_Data_Precentages5[,1:50])))
corrplot(cor(as.matrix(WVS_Data_Precentages5[,101:150])))
corrplot(cor(V136_Count))
nonnormal_variables_names <- rownames(nonnormal_variables)
normal_variable_pca <- WVS_Data_Precentages5[,!colnames(WVS_Data_Precentages5) %in% nonnormal_variables_names]
Normal_PCA_Analysis <- prcomp(normal_variable_pca)
summar(Normal_PCA_Analysis)
summary(Normal_PCA_Analysis)
plot(Normal_PCA_Analysis, main = "ScreePlot", type = "l")
PCA_Analysis_Data <- WVS_Data_Precentages5
PCA_Analysis <-prcomp(PCA_Analysis_Data)
summary(PCA_Analysis)
Burt_Matrix <- crossprod(WVS_Data_Precentages5, y=NULL)
Burt_Matrix <- crossprod(as.matrix(WVS_Data_Precentages5, y=NULL))
View(Burt_Matrix)
Burt_Matrix <- crossprod(as.matrix(WVS_Data_Precentages5[1,], y=NULL))
View(Burt_Matrix)
View(Burt_Matrix)
?mirt
install_github('philchalmers/mirt')
library('devtools')
install.packages("devtools")
library('devtools')
install_github('philchalmers/mirt')
install_github('philchalmers/mirt')
?mirt
model1 <- mirt(WVS_Data_Precentages5)
install_github('philchalmers/mirt')
?philchalmers/mirt
?mirt
model1 <- mirt(WVS_Data_Precentages5, 1)
